# @package _global_
# ViT feature reconstruction on MOVI-E.
defaults:
  - /experiment/projects/bridging/dinosaur/_base_feature_recon
  - /dataset: movi_e_image
  - /experiment/projects/bridging/dinosaur/_preprocessing_movi_dino_feature_recon
  - /experiment/projects/bridging/dinosaur/_metrics_clevr_patch
  - _self_

logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  notes: null
  tags: null
  offline: false
  group: ${hydra:runtime.choices.dataset}
  project: ocl-pool

training_vis_frequency: 10000

# The following parameters assume training on 8 GPUs, leading to an effective batch size of 64.
trainer:
  devices: 8
  max_steps: 500000
  max_epochs:
  check_val_every_n_epoch: null
  val_check_interval: 5000

dataset:
  num_workers: 4
  batch_size: 8

experiment:
  input_feature_dim: 768

models:
  conditioning:
    _target_: routed.ocl.conditioning.RandomConditioning
    n_slots: 24
    object_dim: 128

    batch_size_path: input.batch_size
  feature_extractor:
    model_name: vit_base_patch8_224_dino
    pretrained: ${when_testing:false,true}
    freeze: true

  object_decoder:
    _target_: routed.ocl.decoding.PatchDecoder
    num_patches: 784
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [1024, 1024, 1024]
    object_features_path: perceptual_grouping.objects

  masks_as_image:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: object_decoder.masks
    size: 128
    resize_mode: bilinear
    patch_mode: true
